{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reload method is important when making changes in the code in the file.\n",
    "import testing\n",
    "importlib.reload(testing)\n",
    "import loglinear\n",
    "importlib.reload(loglinear)\n",
    "import grad_check\n",
    "importlib.reload(grad_check)\n",
    "import config\n",
    "importlib.reload(config)\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### part 1 running the grad_check sanity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sanity checks...\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grad_check.sanity_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### part 2 running the built-in sanity checks in loglinear.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26894142 0.73105858]\n",
      "[0.26894142 0.73105858]\n",
      "[0.73105858 0.26894142]\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "exec(open('loglinear.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### part3 training loglinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problem dimensions are: (600, 6)\n",
      "I 0, train_loss [[0.74726506]], train_accuracy 0.9031705227077977, dev_accuracy 0.8033333333333333\n",
      "I 1, train_loss [[0.02770769]], train_accuracy 0.9562982005141388, dev_accuracy 0.8566666666666667\n",
      "I 2, train_loss [[0.05783995]], train_accuracy 0.9802913453299057, dev_accuracy 0.8566666666666667\n",
      "I 3, train_loss [[0.02761137]], train_accuracy 0.9892887746358183, dev_accuracy 0.85\n",
      "I 4, train_loss [[0.05970852]], train_accuracy 0.991859468723222, dev_accuracy 0.8633333333333333\n",
      "I 5, train_loss [[3.76098486e-10]], train_accuracy 0.9948586118251928, dev_accuracy 0.8433333333333334\n",
      "I 6, train_loss [[0.00493217]], train_accuracy 0.9970008568980291, dev_accuracy 0.85\n",
      "I 7, train_loss [[0.03700755]], train_accuracy 0.9974293059125964, dev_accuracy 0.8566666666666667\n",
      "I 8, train_loss [[8.76714036e-08]], train_accuracy 0.9978577549271637, dev_accuracy 0.86\n",
      "early stopping criterion in iteration 9 - detriorating dev accuracy\n",
      "top 7 scores for each language:\n",
      "language: ['it'] bigrams: [('o ', 1.32), ('i ', 1.24), ('ss', 0.94), ('gi', 1.05), ('zi', 0.94), ('e!', 1.0), ('@g', 0.98)]\n",
      "language: ['nl'] bigrams: [('en', 0.98), ('ee', 1.44), ('g ', 1.04), (' k', 0.94), ('oe', 1.4), ('ij', 1.73), ('zo', 1.03)]\n",
      "language: ['en'] bigrams: [('t ', 0.89), (' w', 1.13), ('y ', 1.26), ('d ', 1.08), ('th', 1.57), (' y', 0.86), ('gh', 0.93)]\n",
      "language: ['es'] bigrams: [('o ', 1.1), ('ue', 1.28), ('si', 1.04), ('ad', 1.27), (' y', 1.43), ('aj', 1.17), ('ej', 1.06)]\n",
      "language: ['de'] bigrams: [('ch', 1.21), ('ic', 1.07), (' w', 1.1), ('ei', 1.59), ('au', 0.95), ('ut', 1.09), (':d', 1.0)]\n",
      "language: ['fr'] bigrams: [(' p', 1.05), ('ou', 1.96), ('ai', 1.35), ('oi', 1.47), (' !', 1.41), (\"'e\", 1.16), ('@t', 1.13)]\n"
     ]
    }
   ],
   "source": [
    "exec(open('train_loglin.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### part 4 predict on test\n",
    "we run the loglin training again this time with a configuration telling it to use the trained classifier to predict.\n",
    "\n",
    "The parameter is changed in config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problem dimensions are: (600, 6)\n",
      "I 0, train_loss [[1.43742074e-07]], train_accuracy 0.9400171379605827, dev_accuracy 0.83\n",
      "I 1, train_loss [[0.00974763]], train_accuracy 0.967866323907455, dev_accuracy 0.8466666666666667\n",
      "I 2, train_loss [[0.05521206]], train_accuracy 0.9794344473007712, dev_accuracy 0.8333333333333334\n",
      "I 3, train_loss [[1.04477693e-09]], train_accuracy 0.9880034275921166, dev_accuracy 0.84\n",
      "I 4, train_loss [[0.01899616]], train_accuracy 0.9914310197086547, dev_accuracy 0.8366666666666667\n",
      "I 5, train_loss [[0.0001213]], train_accuracy 0.9948586118251928, dev_accuracy 0.8433333333333334\n",
      "I 6, train_loss [[7.79330196e-07]], train_accuracy 0.9970008568980291, dev_accuracy 0.8566666666666667\n",
      "early stopping criterion in iteration 7 - detriorating dev accuracy\n",
      "top 7 scores for each language:\n",
      "language: ['it'] bigrams: [('o ', 1.21), ('i ', 1.28), ('ss', 0.94), ('gi', 1.0), ('iv', 0.88), ('gl', 0.89), ('@g', 0.93)]\n",
      "language: ['nl'] bigrams: [('ee', 1.44), ('oo', 0.93), ('g ', 1.05), ('je', 0.89), ('oe', 1.33), ('ij', 1.55), ('ze', 0.98)]\n",
      "language: ['en'] bigrams: [(' w', 1.15), ('y ', 1.31), ('d ', 1.07), ('th', 1.51), ('yo', 0.81), ('wh', 0.8), ('gh', 0.9)]\n",
      "language: ['es'] bigrams: [('o ', 1.12), ('ue', 1.23), ('si', 0.96), ('ad', 1.18), (' y', 1.22), ('aj', 1.06), ('ej', 1.02)]\n",
      "language: ['de'] bigrams: [('ch', 1.04), ('ie', 0.91), ('ic', 1.14), (' w', 1.01), ('ei', 1.56), ('ut', 1.05), (':d', 1.04)]\n",
      "language: ['fr'] bigrams: [(' p', 0.97), ('ou', 1.86), ('ai', 1.3), ('oi', 1.46), (' !', 1.29), (\"'e\", 1.06), (\"'a\", 0.99)]\n",
      "\n",
      "\n",
      "\n",
      "saving predictions for test data, size: 300\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(config)\n",
    "exec(open('train_loglin.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### part 5 mlp with 1 hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b_tag\n",
      "Gradient check passed!\n",
      "U:\n",
      "Gradient check passed!\n",
      "b:\n",
      "Gradient check passed!\n",
      "W:\n",
      "Gradient check passed!\n",
      "b_tag\n",
      "Gradient check passed!\n",
      "U:\n",
      "Gradient check passed!\n",
      "b:\n",
      "Gradient check passed!\n",
      "W:\n",
      "Gradient check passed!\n",
      "b_tag\n",
      "Gradient check passed!\n",
      "U:\n",
      "Gradient check passed!\n",
      "b:\n",
      "Gradient check passed!\n",
      "W:\n",
      "Gradient check passed!\n",
      "b_tag\n",
      "Gradient check passed!\n",
      "U:\n",
      "Gradient check passed!\n",
      "b:\n",
      "Gradient check passed!\n",
      "W:\n",
      "Gradient check passed!\n",
      "b_tag\n",
      "Gradient check passed!\n",
      "U:\n",
      "Gradient check passed!\n",
      "b:\n",
      "Gradient check passed!\n",
      "W:\n",
      "Gradient check passed!\n",
      "b_tag\n",
      "Gradient check passed!\n",
      "U:\n",
      "Gradient check passed!\n",
      "b:\n",
      "Gradient check passed!\n",
      "W:\n",
      "Gradient check passed!\n",
      "b_tag\n",
      "Gradient check passed!\n",
      "U:\n",
      "Gradient check passed!\n",
      "b:\n",
      "Gradient check passed!\n",
      "W:\n",
      "Gradient check passed!\n",
      "b_tag\n",
      "Gradient check passed!\n",
      "U:\n",
      "Gradient check passed!\n",
      "b:\n",
      "Gradient check passed!\n",
      "W:\n",
      "Gradient check passed!\n",
      "b_tag\n",
      "Gradient check passed!\n",
      "U:\n",
      "Gradient check passed!\n",
      "b:\n",
      "Gradient check passed!\n",
      "W:\n",
      "Gradient check passed!\n",
      "b_tag\n",
      "Gradient check passed!\n",
      "U:\n",
      "Gradient check passed!\n",
      "b:\n",
      "Gradient check passed!\n",
      "W:\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# testing the gradients\n",
    "import mlp1\n",
    "\n",
    "testing.mlp1_grad_sanity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yhat counter: Counter({1: 61, 3: 56, 4: 47, 5: 47, 0: 45, 2: 44})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8633333333333333"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import train_loglin as tl\n",
    "\n",
    "\n",
    "train_data = utils.read_data(config.filename_train)\n",
    "symbol_dict = initialize_symbol_dict(train_data)\n",
    "label_dict = initialize_label_dict(train_data)\n",
    "xy_train = list(xy_generator(train_data, utils.text_to_bigrams, symbol_dict, label_dict))\n",
    "\n",
    "dev_data = utils.read_data(config.filename_dev)\n",
    "xy_dev = list(xy_generator(dev_data, utils.text_to_bigrams, symbol_dict, label_dict))\n",
    "\n",
    "tl.accuracy_on_dataset(xy_dev, trained_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 6)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_params[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_gb = testing.grad_sanity()\n",
    "W,b = testing.create_classifier(3,6)\n",
    "print(W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loglinear.logloss(np.array([0,1,0]),np.array([0.333333,0.4333,0.2333]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(testing)\n",
    "#importlib.reload(loglinear)\n",
    "#importlib.reload(grad_check)\n",
    "p = testing.grad_sanity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import config\n",
    "importlib.reload(utils)\n",
    "importlib.reload(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=utils.read_data(config.filename_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.text_to_bigrams(a[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "f=Counter()\n",
    "f.update(['a','b','c'])\n",
    "f.update(['a','d','x'])\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{i:x for i,x in enumerate(f)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{x:y for x,y in f.most_common(1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros(5, np.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import train_loglin as tl\n",
    "import config\n",
    "import loglinear as ll\n",
    "importlib.reload(utils)\n",
    "importlib.reload(tl)\n",
    "importlib.reload(config)\n",
    "importlib.reload(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = utils.read_data(config.filename_train)\n",
    "symbol_dict = tl.initialize_symbol_dict(train_data)\n",
    "label_dict = tl.initialize_label_dict(train_data)\n",
    "xy_train = list(tl.xy_generator(train_data, utils.text_to_bigrams, symbol_dict, label_dict))\n",
    "\n",
    "dev_data = utils.read_data(config.filename_dev)\n",
    "xy_dev = list(tl.xy_generator(dev_data, utils.text_to_bigrams, symbol_dict, label_dict))\n",
    "in_dim = min(config.max_count, len(symbol_dict))\n",
    "out_dim = len(label_dict)\n",
    "print(\"problem dimensions are: {}\".format((in_dim, out_dim)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = ll.create_classifier(in_dim, out_dim)\n",
    "trained_params = tl.train_classifier(xy_train, xy_dev, config.num_iterations, config.learning_rate, params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=next(xy)\n",
    "print((x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(k,v) for k,v in symbol_dict.items() if v in [  0,   3,   7,   8,  11,  12,  13,  16,  19,  22,  23,  25,  29, 54]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_xy=list(xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(big_xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_xy[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([1., 2., 3.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(x,ndmin=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.array([1,2,3])\n",
    "b=np.array([4,5,6])\n",
    "p=(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in p:\n",
    "    t[2]=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([True, True ,False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### testing mlp1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlp1\n",
    "importlib.reload(mlp1)\n",
    "import testing\n",
    "importlib.reload(testing)\n",
    "import loglinear as ll\n",
    "importlib.reload(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W,b,U, b_tag = mlp1.create_classifier(12,4,6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.ones((1,12), np.double)\n",
    "y = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = testing.randomize_array(W)\n",
    "b = testing.randomize_array(b)\n",
    "U = testing.randomize_array(U)\n",
    "b_tag = testing.randomize_array(b_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_e, y_hat, loss, y_diff = mlp1.loss_and_gradients(x,y,(W,b,U,b_tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_e)\n",
    "print(y_hat)\n",
    "print(loss)\n",
    "print(y_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll.logloss(y, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for small x, with W = I (the unit matrix) and b=0, we expect the result to be the same as for loglinear classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W,b,U, b_tag = mlp1.create_classifier(12,12,6)\n",
    "W = np.eye(12)\n",
    "x = np.random.rand(1,12)*0.1\n",
    "U = testing.randomize_array(U)\n",
    "b_tag = testing.randomize_array(b_tag)\n",
    "loss2 = mlp1.loss_and_gradients(x,4,(W,b,U,b_tag))\n",
    "loss1,_ = ll.loss_and_gradients(x,4,(U,b_tag))\n",
    "print(loss1, loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - np.array([[1.,2.,3.]]) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### now testing the gradient calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import testing\n",
    "importlib.reload(testing)\n",
    "import mlp1\n",
    "importlib.reload(mlp1)\n",
    "import loglinear as ll\n",
    "importlib.reload(ll)\n",
    "import grad_check\n",
    "importlib.reload(grad_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing.mlp1_grad_sanity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.diag(np.array([-1000,1\n",
    "                  ,1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.diag(np.squeeze(1- np.round(a[0]) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.tile(np.array([[1,2,3]]),(3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([[1.,2.,3.]]) * np.array([[4.,5.,6.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training mlp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "importlib.reload(config)\n",
    "import train_loglin\n",
    "importlib.reload(train_loglin)\n",
    "import mlp1\n",
    "importlib.reload(mlp1)\n",
    "import train_mlp1\n",
    "importlib.reload(train_mlp1)\n",
    "trained_params = train_mlp1.main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### same thing running the code in train_mlp1 main directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codepath = 'C:\\\\Shahar\\\\BarIlan\\\\NLP-courses\\\\89687-DL\\\\Assignment1\\\\code'\n",
    "from os import path\n",
    "exec(open(path.join(codepath,'train_mlp1.py')).read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### testing parts of mlpn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlpn\n",
    "importlib.reload(mlpn)\n",
    "import testing\n",
    "importlib.reload(testing)\n",
    "import grad_check\n",
    "importlib.reload(grad_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = mlpn.create_classifier([5,6,7,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = mlpn.create_classifier([5,5,5,5])\n",
    "[p.shape for p in params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params[::2]=[np.eye(5) for i in range(3)] \n",
    "[p.shape for p in params]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### test feedforward step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W=np.eye(5)\n",
    "b=np.zeros((1,5))\n",
    "a_in = np.array(np.arange(0,0.5,0.1), np.double, ndmin=2)\n",
    "\n",
    "z,a_out = mlpn.layer_ff(a_in,(W,b),np.tanh)\n",
    "\n",
    "print(\"a_in: {}\\n z:{}\\n a_out: {}\".format(a_in, z, a_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(a_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this tests the feedforward code by building a \n",
    "# network of 3 identity (eye matrix) hidden layers\n",
    "x = np.random.randn(5)*0.1\n",
    "print(\"x: {}, \\nsoftmax: {}\".format(x, ll.softmax(x)))\n",
    "\n",
    "y = mlpn.feedforward_loop(x, params)\n",
    "\n",
    "for i, az in enumerate(y):\n",
    "    a, z = az\n",
    "    print(\"{}\\na:\\n{}\\nz:\\n{}\".format(i,a,z))\n",
    "[(t[0].shape, t[1].shape) for t in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after seeing the whole feedforward progression, let's check the \n",
    "# small function that gets x and returns the final a\n",
    "mlpn.classifier_output(x,params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### testing the backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpn.classifier_output(np.array([[1.,0.,0.,0.,0.]]),params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpn.loss_and_gradients(np.array([[1.,1.,0.,0.,0.]]),0,params)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpn.create_classifier([3,4,6])[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import mlpn\n",
    "importlib.reload(mlpn)\n",
    "import testing\n",
    "importlib.reload(testing)\n",
    "import grad_check\n",
    "importlib.reload(grad_check)\n",
    "\n",
    "testing.mlpn_grad_sanity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### comparing the output of training with mlp1 and mlpn when configured to same topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "importlib.reload(config)\n",
    "import train_loglin\n",
    "importlib.reload(train_loglin)\n",
    "import mlpn\n",
    "importlib.reload(mlpn)\n",
    "import train_mlpn\n",
    "importlib.reload(train_mlpn)\n",
    "import utils\n",
    "trained_params = train_mlpn.main(utils.text_to_bigrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(config)\n",
    "importlib.reload(train_mlpn)\n",
    "trained_params = train_mlpn.main(utils.text_to_bigrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(config)\n",
    "import train_mlp1\n",
    "importlib.reload(train_mlp1)\n",
    "trained_params = train_mlp1.main(utils.text_to_bigrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    np.random.seed(335)\n",
    "    x = np.array(range(5))\n",
    "    for j in range(3):\n",
    "        np.random.shuffle(x)\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= [('a',5),('b',4),('k',7)]\n",
    "np.random.shuffle(x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bari_env",
   "language": "python",
   "name": "bari_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
