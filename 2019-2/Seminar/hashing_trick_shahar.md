## Compressing Neural Networks With the Hashing Trick

![hashing_trick](Seminar/Hashing_trick_illustration.png)

---

### Deep learning concise timeline
* 1957 - Invention of perceptron
* 1970s - First AI winter
* 1982 - Backpropagation applied to Multi-Layer Perceptrons
* 2000s - Second AI winter
* 2012 - ImageNet (ILSVRC) Won by AlexNet (5 Layers, 60 Million parameters)
* 2012 onward - Deep learning boom
    * Higher Percision on benchmarks
    * Proliferation of methods
    * Application in more fields
    * Larger networks

---

### Motivations for reducing size of network
* Shorten response latency (improved user experience)
* Reduce operational costs
* Democratize AI (lower overhead costs)
* Run on mobile devices (instead of cloud solution)

---

### Network compression - Main approaches
* "Brain Damage"
* Multiply two matrices
* Distillation/ Dark-knowledge

