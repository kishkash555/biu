{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ex1_embed_mat50.pickle','rb') as a:\n",
    "    E = pickle.load(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50L, 43129L)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.598446355544638"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.sum(E,axis=0)==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, OrderedDict\n",
    "def scan_train_for_vocab(train_data):\n",
    "    words = Counter()\n",
    "    tags = Counter()\n",
    "    for line in train_data:\n",
    "        if len(line) > 1:\n",
    "            word, tag = line.split()\n",
    "            words[word] += 1\n",
    "            tags[tag] += 1\n",
    "        \n",
    "    word_list = [a for a, _ in words.most_common()]\n",
    "    tag_list = [a for a, _ in tags.most_common()]\n",
    "    word_dict = OrderedDict((a,i) for i, a in enumerate(word_list))\n",
    "    tag_dict = OrderedDict((a,i) for i, a in enumerate(tag_list))\n",
    "    return word_dict, tag_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('../pos/train','rt') as a:\n",
    "    word_dict,tag_dict = scan_train_for_vocab(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, ['own', 'bank', 'profit', 'big', 'recent', 'products', 'being', 'should', 'analysts', 'these'])\n",
      "(210, ['debt', 'part', 'securities', 'including', 'higher', '15', 'offer', 'well', 'work', 'tax'])\n",
      "(220, ['8', 'past', 'reported', 'operations', 'take', 'her', 'sale', 'This', 'Japan', 'funds'])\n",
      "(230, ['?', 'If', 'lower', 'House', 'way', '1988', 'end', 'plans', 'she', 'increase'])\n",
      "(240, ['closed', 'both', 'sold', 'yield', 'Friday', 'during', 'very', 'less', 'loss', 'Bank'])\n",
      "(250, ['markets', 'vice', 'growth', 'bid', 'each', 'where', 'another', 'costs', 'issues', 'how'])\n",
      "(260, ['pay', 'our', 'used', 'Bush', 'five', 'As', 'economic', 'due', 'National', 'few'])\n",
      "(270, [\"'re\", 'high', 'average', 'common', '20', 'several', 'him', 'good', 'use', 'current'])\n",
      "(280, ['banks', 'British', 'yen', 'cash', 'At', 'day', 'third', 'then', 'least', 'San'])\n",
      "(290, ['revenue', '50', '2', 'Stock', 'California', 'report', 'foreign', 'might', '1989', 'assets'])\n"
     ]
    }
   ],
   "source": [
    "for i in range(200,300,10):\n",
    "    print(i,word_dict.keys()[i:i+10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'share'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict.keys()[62]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = E[:,62]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = [cosine(E[:,i],v) for i in xrange(43129)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43129"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "distnp = np.array(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    2,   115,   609,  2229, 11124, 18476,  8391,  1556,   552,\n",
       "           75], dtype=int64),\n",
       " array([0.        , 0.18548872, 0.37097744, 0.55646616, 0.74195488,\n",
       "        0.9274436 , 1.11293232, 1.29842104, 1.48390976, 1.66939848,\n",
       "        1.8548872 ]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.histogram(distnp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  62,   88,  134,  269,  565, 1215], dtype=int64),)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nonzero(distnp<0.22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'still'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict.keys()[176]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['share', 'because', 'so', 'few', 'July', 'minimum']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word_dict.keys()[i] for i in [  62,   88,  134,  269,  565, 1215]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'year'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict.keys()[39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['share',\n",
       " 'because',\n",
       " 'so',\n",
       " 'still',\n",
       " 'few',\n",
       " 'July',\n",
       " 'key',\n",
       " 'minimum',\n",
       " 'ease',\n",
       " '45-year-old']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = E[:,62]\n",
    "dist_year = np.array([cosine(E[:,i],v) for i in xrange(43129)])\n",
    "[word_dict.keys()[i] for i in np.nonzero(dist_year< sorted(dist_year)[10])[0].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['year',\n",
       " 'Last',\n",
       " 'arrested',\n",
       " 'Congressional',\n",
       " 'canning',\n",
       " '10.43',\n",
       " 'Evaluating',\n",
       " '32-nation',\n",
       " 'Honors',\n",
       " '390-million']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = E[:,39]\n",
    "dist_year = np.array([cosine(E[:,i],v) for i in xrange(43129)])\n",
    "[word_dict.keys()[i] for i in np.nonzero(dist_year< sorted(dist_year)[10])[0].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['%',\n",
       " 'be',\n",
       " 'only',\n",
       " 'can',\n",
       " 'technique',\n",
       " 'managements',\n",
       " 'pillowcases',\n",
       " '60-inch',\n",
       " 'plugged',\n",
       " '120,000-employee']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = E[:,94]\n",
    "dist_year = np.array([cosine(E[:,i],v) for i in xrange(43129)])\n",
    "[word_dict.keys()[i] for i in np.nonzero(dist_year< sorted(dist_year)[10])[0].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['also',\n",
       " 'Japan',\n",
       " 'network',\n",
       " 'contributed',\n",
       " 'Hewlett-Packard',\n",
       " 'Virginia',\n",
       " 'Pa.',\n",
       " 'Commonwealth',\n",
       " '6,400',\n",
       " 'high-minded']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = E[:,63]\n",
    "dist_year = np.array([cosine(E[:,i],v) for i in xrange(43129)])\n",
    "[word_dict.keys()[i] for i in np.nonzero(dist_year< sorted(dist_year)[10])[0].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Stock',\n",
       " 'late',\n",
       " 'number',\n",
       " 'Like',\n",
       " 'Besides',\n",
       " 'middlemen',\n",
       " 'successors',\n",
       " 'non-Communist',\n",
       " '4.35',\n",
       " 'dynasty']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = E[:,293]\n",
    "dist_year = np.array([cosine(E[:,i],v) for i in xrange(43129)])\n",
    "[word_dict.keys()[i] for i in np.nonzero(dist_year< sorted(dist_year)[10])[0].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = np.fromfile('../wordVectors.txt', sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100232L, 50L)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E = E.reshape(E.shape[0]/50,50)\n",
    "E.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.172414, -0.091063,  0.255125, -0.837163,  0.434872, -0.499848,\n",
       "       -0.042904, -0.059642, -0.635087, -0.458795, -0.105671,  0.506513,\n",
       "       -0.105105, -0.405678,  0.493365,  0.408807,  0.401635, -0.817805,\n",
       "        0.62634 ,  0.580636, -0.246996, -0.008515, -0.67114 ,  0.301865,\n",
       "       -0.439651,  0.247694, -0.291402,  0.873009,  0.216212,  0.145576,\n",
       "       -0.211101, -0.35236 ,  0.227651, -0.118416,  0.371816,  0.261296,\n",
       "        0.017548,  0.596692, -0.485722, -0.36953 , -0.048807,  0.01796 ,\n",
       "       -0.040483,  0.111193,  0.398039,  0.162765,  0.408946,  0.005343,\n",
       "       -0.107523, -0.079821])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu = lambda word: len(set(word) - set('-+,.0123456789')) ==0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nu('1,456.24w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set('1456') - set('-+,.0123456789')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'my-god'.rsplit('-',1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
